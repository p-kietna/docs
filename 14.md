Hereâ€™s how you can rewrite your `reduce`-based chunk uploader using a `for await...of` loop to support sequential execution, `Promise.allSettled`, and retry logic â€” all while avoiding ESLintâ€™s `no-await-in-loop` warning if needed:

---

### âœ… Refactored Using `for await...of`

```ts
async function uploadChunksWithRetry(
  queue: Array<Array<{ partNumber: number; url: string }>>,
  file: File,
  CHUNK_SIZE: number,
  signal: AbortSignal
) {
  const retryQueue: Array<Array<{ partNumber: number; url: string }>> = [...queue];

  for await (const chunk of retryQueue) {
    const results = await Promise.allSettled(
      chunk.map(async ({ partNumber, url }) => {
        const start = (partNumber - 1) * CHUNK_SIZE;
        const end = Math.min(start + CHUNK_SIZE, file.size);
        const part = file.slice(start, end);

        await axios.put(url, part, {
          signal,
          headers: {
            'Content-Type': file.type,
          },
        });
      })
    );

    const failed = chunk.filter((_, i) => results[i]?.status === 'rejected');
    console.log("ðŸš€ ~ failed:", failed.map(f => f.partNumber));

    if (failed.length > 0) {
      console.warn(`Retrying ${failed.length} failed files...`);
      retryQueue.push(failed); // âœ… Reinsert failed chunk for retry
    }
  }
}
```

---

### ðŸ§  Key Notes

- `for await...of` works because `retryQueue` is treated as an async iterable.
- This loop runs sequentially, waiting for each chunk to finish before moving to the next.
- Failed chunks are reinserted at the end of the queue for retry.
- You can disable ESLintâ€™s `no-await-in-loop` rule locally if needed:

```ts
/* eslint-disable no-await-in-loop */
```

---

Let me know if you want to add retry limits, exponential backoff, or progress tracking â€” I can help you make this uploader resilient and user-friendly.