Ah, now I get it â€” you're describing a **streamed, interleaved upload system** where:

- You start uploading a chunk of 10 parts.
- As soon as **any part** (e.g. the 3rd) finishes, you want to **immediately begin** uploading the next part from the following chunk (e.g. the 1st part of chunk 2).
- This creates a **rolling pipeline** of uploads, rather than waiting for all 10 parts to finish before starting the next chunk.

---

### âœ… Strategy: Rolling Upload Queue with Concurrency Control

To achieve this, you need:

1. A **global queue** of all parts (not grouped by chunk).
2. A **concurrency limit** (e.g. 10 uploads at a time).
3. A system that **starts a new upload immediately** when one finishes.

This is best done with a **task pool** or **semaphore pattern**.

---

### ðŸ§© Code Sketch: Rolling Upload with Dynamic Dispatch

```ts
async function rollingUpload(
  allParts: Array<{ partNumber: number; url: string }>,
  file: File,
  CHUNK_SIZE: number,
  signal: AbortSignal,
  maxConcurrent = 10
) {
  const queue = [...allParts];
  let active = 0;

  return new Promise<void>((resolve, reject) => {
    const failedParts: typeof allParts = [];

    const next = async () => {
      if (queue.length === 0 && active === 0) {
        return resolve(); // all done
      }

      while (active < maxConcurrent && queue.length > 0) {
        const part = queue.shift();
        if (!part) continue;

        active++;

        const { partNumber, url } = part;
        const start = (partNumber - 1) * CHUNK_SIZE;
        const end = Math.min(start + CHUNK_SIZE, file.size);
        const chunk = file.slice(start, end);

        axios.put(url, chunk, {
          signal,
          headers: {
            'Content-Type': file.type,
          },
        })
          .catch(() => {
            failedParts.push(part); // collect failed part
          })
          .finally(() => {
            active--;
            next(); // trigger next upload
          });
      }
    };

    next(); // kick off initial uploads
  });
}
```

---

### ðŸ§  How It Works

- Starts up to `maxConcurrent` uploads.
- Each time one finishes, it immediately triggers the next.
- No need to wait for a full chunk â€” uploads flow continuously.
- You can group parts by chunk if needed, but the queue is flat.

---

Let me know if you want to add retry logic, progress tracking, or pause/resume support â€” this pattern is perfect for building a high-performance uploader.