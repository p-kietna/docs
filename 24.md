You're absolutely right â€” and you're describing a classic async control issue: your `uploadPartsStreamed` function must **fully await all uploads** before the next action runs. If `axios.put` isn't awaited properly inside that function, the uploads will still be in progress when your next action executes â€” causing errors or incomplete data.

---

### âœ… How to Fix It: Ensure All Uploads Are Awaited

In your current `uploadPartsStreamed` function, you're using `axios.put(...).finally(() => next())` without `await`, which means the function returns before uploads finish.

To fix this, you need to:

1. **Track all upload promises**
2. **Await them before resolving**

---

### ðŸ”§ Updated `uploadPartsStreamed` with Proper Await

```ts
async function uploadPartsStreamed(
  chunks: Array<Array<{ partNumber: number; url: string }>>,
  file: File,
  CHUNK_SIZE: number,
  signal: AbortSignal,
  maxConcurrent = 5
): Promise<void> {
  const partQueue = chunks.flat();
  const failedParts: typeof partQueue = [];
  const uploadPromises: Promise<void>[] = [];

  const uploadPart = async (part: { partNumber: number; url: string }) => {
    const { partNumber, url } = part;
    const start = (partNumber - 1) * CHUNK_SIZE;
    const end = Math.min(start + CHUNK_SIZE, file.size);
    const chunk = file.slice(start, end);

    try {
      await axios.put(url, chunk, {
        signal,
        headers: {
          'Content-Type': file.type,
        },
      });
    } catch {
      failedParts.push(part);
    }
  };

  const runPool = async () => {
    const pool: Promise<void>[] = [];

    while (partQueue.length > 0) {
      while (pool.length < maxConcurrent && partQueue.length > 0) {
        const part = partQueue.shift();
        if (part) {
          const promise = uploadPart(part);
          pool.push(promise);
          promise.finally(() => {
            pool.splice(pool.indexOf(promise), 1);
          });
        }
      }
      await Promise.race(pool); // wait for one to finish before adding more
    }

    await Promise.all(pool); // wait for remaining uploads
  };

  await runPool(); // âœ… ensures all uploads are done before continuing

  if (failedParts.length > 0) {
    console.warn(`Retrying ${failedParts.length} failed parts...`);
    // Optionally: retry failedParts here
  }
}
```

---

### ðŸ§  Why This Works

- `await runPool()` ensures all uploads finish before returning.
- `Promise.race(pool)` lets you refill the pool as soon as one finishes.
- `Promise.all(pool)` waits for the final batch to complete.
- Your next action can now safely run **after** `await uploadPartsStreamed(...)`.

---

Let me know if you want to add retry limits, exponential backoff, or progress tracking â€” this pattern is perfect for building a high-performance uploader.