To adapt your `uploadFilesInChunks` logic to the `reduce`-based sequential chunk upload pattern, here's how you can refactor it. This version uploads chunks sequentially, and within each chunk, uploads files in parallel â€” similar to your `axios.put` example:

---

### âœ… Refactored Version Using `reduce`

```ts
const uploadFilesInChunks = async (files: File[], chunkSize = 10) => {
  const chunks: File[][] = [];

  // Split files into chunks
  for (let i = 0; i < files.length; i += chunkSize) {
    chunks.push(files.slice(i, i + chunkSize));
  }

  await chunks.reduce(async (prevPromise, chunk) => {
    await prevPromise;

    await Promise.all(
      chunk.map(async (file) => {
        try {
          await uploadSingleFile(file);
        } catch (err) {
          console.error(`Upload failed for ${file.name}`, err);
          // Optionally: collect failed files for retry
        }
      })
    );
  }, Promise.resolve());
};
```

---

### ðŸ§  Notes

- This ensures **sequential chunk uploads**: one chunk finishes before the next starts.
- Inside each chunk, files are uploaded **in parallel**.
- You can add retry logic or collect failed files if needed.

---

Let me know if you want to add progress tracking, retry failed files after all chunks finish, or throttle concurrency for better performance.
